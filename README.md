# YAMNet éŸ³é¢‘åˆ†ç±»æµ‹è¯•åº”ç”¨ / YAMNet Audio Classification Test App

<div align="center">

[![Flutter](https://img.shields.io/badge/Flutter-3.0+-blue.svg)](https://flutter.dev/)
[![TensorFlow Lite](https://img.shields.io/badge/TensorFlow%20Lite-0.11.0-orange.svg)](https://www.tensorflow.org/lite)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**åŸºäº Flutter + TensorFlow Lite çš„å®æ—¶éŸ³é¢‘åˆ†ç±»åº”ç”¨**  
**Real-time audio classification app built with Flutter + TensorFlow Lite**

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

</div>

---

## ä¸­æ–‡

### ğŸ¯ é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªåŸºäº **Flutter** å’Œ **TensorFlow Lite** çš„å®æ—¶éŸ³é¢‘åˆ†ç±»æµ‹è¯•åº”ç”¨ï¼Œä½¿ç”¨ **YAMNet** æ¨¡å‹è¿›è¡Œé«˜ç²¾åº¦éŸ³é¢‘è¯†åˆ«ã€‚åº”ç”¨æ”¯æŒ 521 ç§éŸ³é¢‘ç±»åˆ«çš„è¯†åˆ«ï¼ŒåŒ…æ‹¬è¯­éŸ³ã€åŠ¨ç‰©å£°éŸ³ã€ç¯å¢ƒå£°éŸ³ã€éŸ³ä¹ç­‰ã€‚

### âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸµ **å®æ—¶éŸ³é¢‘åˆ†ç±»**: åŸºäº YAMNet æ¨¡å‹çš„ 522 ç§éŸ³é¢‘ç±»åˆ«è¯†åˆ«
- ğŸ”’ **æœ¬åœ°å¤„ç†**: æ‰€æœ‰éŸ³é¢‘æ•°æ®åœ¨æœ¬åœ°å¤„ç†ï¼Œä¿æŠ¤ç”¨æˆ·éšç§
- ğŸ **Apple-level æƒé™ç®¡ç†**: æ™ºèƒ½æƒé™æ£€æµ‹å’Œä¼˜é›…çš„ç”¨æˆ·ä½“éªŒ
- ğŸ“± **ç°ä»£åŒ– UI**: ç®€æ´ç¾è§‚çš„ç”¨æˆ·ç•Œé¢å’Œå®æ—¶çŠ¶æ€åé¦ˆ
- âš¡ **é«˜æ€§èƒ½**: ä½¿ç”¨ TensorFlow Lite è¿›è¡Œé«˜æ•ˆæ¨ç†

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### ç¯å¢ƒè¦æ±‚
- Flutter 3.0+
- Dart 3.0+
- Android SDK / iOS SDK

#### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
```bash
git clone https://github.com/didadidaboom/yamnet-test-app.git
cd yamnet-test-app
```

2. **å®‰è£…ä¾èµ–**
```bash
flutter pub get
```

3. **ç¡®ä¿æ¨¡å‹æ–‡ä»¶**
```
model/
â”œâ”€â”€ yamnet.tflite    # YAMNet TensorFlow Lite æ¨¡å‹
â””â”€â”€ labels.txt       # éŸ³é¢‘åˆ†ç±»æ ‡ç­¾æ–‡ä»¶
```

4. **è¿è¡Œåº”ç”¨**
```bash
flutter run
```

### ğŸ“± ä½¿ç”¨è¯´æ˜

1. **å¯åŠ¨åº”ç”¨**: è‡ªåŠ¨åŠ è½½æ¨¡å‹å’Œæ£€æŸ¥æƒé™
2. **å¼€å§‹å½•éŸ³**: ç‚¹å‡»å½•éŸ³æŒ‰é’®ï¼Œåº”ç”¨ä¼šè¯·æ±‚éº¦å…‹é£æƒé™
3. **åœæ­¢å½•éŸ³**: ç‚¹å‡»åœæ­¢æŒ‰é’®ï¼Œè‡ªåŠ¨åˆ†æéŸ³é¢‘å†…å®¹
4. **æŸ¥çœ‹ç»“æœ**: æ˜¾ç¤ºè¯†åˆ«ç»“æœå’Œç½®ä¿¡åº¦æ’å

### ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **å‰ç«¯æ¡†æ¶**: Flutter 3.0+
- **æœºå™¨å­¦ä¹ **: TensorFlow Lite 0.11.0
- **éŸ³é¢‘å¤„ç†**: flutter_sound 9.2.13
- **æƒé™ç®¡ç†**: permission_handler 11.0.1
- **æ¨¡å‹**: YAMNet (522 ç±»åˆ«éŸ³é¢‘åˆ†ç±»)

### ğŸ“ é¡¹ç›®ç»“æ„

```
yamnet-test-app/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ yamnet_test.dart          # æ ¸å¿ƒéŸ³é¢‘å¤„ç†ç±»
â”‚   â””â”€â”€ yamnet_test_page.dart     # Flutter UI ç•Œé¢
â”œâ”€â”€ model/                        # æ¨¡å‹æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ yamnet.tflite            # YAMNet æ¨¡å‹
â”‚   â””â”€â”€ labels.txt               # åˆ†ç±»æ ‡ç­¾
â”œâ”€â”€ pubspec.yaml                 # é¡¹ç›®é…ç½®
â””â”€â”€ README.md                   # é¡¹ç›®æ–‡æ¡£
```

### ğŸ”§ å¼€å‘è¯´æ˜

#### ä¸»è¦ä¾èµ–
```yaml
dependencies:
  tflite_flutter: ^0.11.0        # TensorFlow Lite
  flutter_sound: ^9.2.13         # éŸ³é¢‘å½•åˆ¶
  permission_handler: ^11.0.1    # æƒé™ç®¡ç†
  app_settings: ^5.1.1           # ç³»ç»Ÿè®¾ç½®
```

#### æ ¸å¿ƒåŠŸèƒ½
- **éŸ³é¢‘å½•åˆ¶**: 16kHz é‡‡æ ·ç‡ï¼Œå•å£°é“å½•éŸ³
- **æ¨¡å‹æ¨ç†**: 0.975ç§’éŸ³é¢‘è¾“å…¥ï¼Œ521ä¸ªç±»åˆ«è¾“å‡º
- **æƒé™ç®¡ç†**: Apple-level æƒé™æ£€æµ‹å’Œè®¾ç½®å¼•å¯¼
- **ç»“æœå¤„ç†**: ç½®ä¿¡åº¦æ’åºå’Œå¯è§†åŒ–å±•ç¤º

### ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

1. Fork æœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

### ğŸ“ ç‰ˆæƒå£°æ˜

å¦‚æœæ‚¨å¼•ç”¨æˆ–ä½¿ç”¨æ­¤ä»£ç ï¼Œè¯·æ³¨æ˜æ¥æºï¼š

GitHub: @didadidaboom

Â© 2024 @didadidaboom. All rights reserved.

This work is licensed under the MIT License. See LICENSE file for details.

---

## English

### ğŸ¯ Project Overview

A real-time audio classification test application built with **Flutter** and **TensorFlow Lite**, using the **YAMNet** model for high-precision audio recognition. The app supports identification of 521 audio categories, including speech, animal sounds, environmental sounds, music, and more.

### âœ¨ Key Features

- ğŸµ **Real-time Audio Classification**: 522 audio category recognition based on YAMNet model
- ğŸ”’ **Local Processing**: All audio data processed locally, protecting user privacy
- ğŸ **Apple-level Permission Management**: Smart permission detection and elegant UX
- ğŸ“± **Modern UI**: Clean and beautiful user interface with real-time status feedback
- âš¡ **High Performance**: Efficient inference using TensorFlow Lite

### ğŸš€ Quick Start

#### Requirements
- Flutter 3.0+
- Dart 3.0+
- Android SDK / iOS SDK

#### Installation

1. **Clone Repository**
```bash
git clone https://github.com/didadidaboom/yamnet-test-app.git
cd yamnet-test-app
```

2. **Install Dependencies**
```bash
flutter pub get
```

3. **Ensure Model Files**
```
model/
â”œâ”€â”€ yamnet.tflite    # YAMNet TensorFlow Lite Model
â””â”€â”€ labels.txt       # Audio Classification Labels
```

4. **Run Application**
```bash
flutter run
```

### ğŸ“± Usage Guide

1. **Launch App**: Automatically loads model and checks permissions
2. **Start Recording**: Tap record button, app will request microphone permission
3. **Stop Recording**: Tap stop button, automatically analyzes audio content
4. **View Results**: Displays recognition results and confidence rankings

### ğŸ› ï¸ Tech Stack

- **Frontend Framework**: Flutter 3.0+
- **Machine Learning**: TensorFlow Lite 0.11.0
- **Audio Processing**: flutter_sound 9.2.13
- **Permission Management**: permission_handler 11.0.1
- **Model**: YAMNet (522-category audio classification)

### ğŸ“ Project Structure

```
yamnet-test-app/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ yamnet_test.dart          # Core Audio Processing Class
â”‚   â””â”€â”€ yamnet_test_page.dart     # Flutter UI Interface
â”œâ”€â”€ model/                        # Model Files Directory
â”‚   â”œâ”€â”€ yamnet.tflite            # YAMNet Model
â”‚   â””â”€â”€ labels.txt               # Classification Labels
â”œâ”€â”€ pubspec.yaml                 # Project Configuration
â””â”€â”€ README.md                   # Project Documentation
```

### ğŸ”§ Development Guide

#### Main Dependencies
```yaml
dependencies:
  tflite_flutter: ^0.11.0        # TensorFlow Lite
  flutter_sound: ^9.2.13         # Audio Recording
  permission_handler: ^11.0.1    # Permission Management
  app_settings: ^5.1.1           # System Settings
```

#### Core Features
- **Audio Recording**: 16kHz sample rate, mono channel recording
- **Model Inference**: 0.975s audio input, 521 category output
- **Permission Management**: Apple-level permission detection and settings guidance
- **Result Processing**: Confidence ranking and visualization

### ğŸ¤ Contributing

Issues and Pull Requests are welcome!

1. Fork this project
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### ğŸ“ Copyright Notice

If you reference or use this code, please cite the source:

GitHub: @didadidaboom

Â© 2024 @didadidaboom. All rights reserved.

This work is licensed under the MIT License. See LICENSE file for details. 
