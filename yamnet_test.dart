import 'dart:math';
import 'dart:typed_data';
import 'dart:io';
import 'dart:async';
import 'package:tflite_flutter/tflite_flutter.dart' hide List;
import 'package:flutter_sound/flutter_sound.dart';
import 'package:flutter/services.dart' show rootBundle;

/// ç®€å•çš„YAMNetéŸ³é¢‘åˆ†ç±»æµ‹è¯•å™¨
class YamnetTest {
  Interpreter? _interpreter;
  FlutterSoundRecorder? _recorder;
  List<String>? _labels;
  
  // éŸ³é¢‘é…ç½® - é€‚é…YAMNetæ¨¡å‹
  static const int _sampleRate = 16000; // YAMNetè¦æ±‚16kHz
  static const int _numChannels = 1;
  static const int _bufferSize = 1024;
  static const Duration _subscriptionDuration = Duration(milliseconds: 100);
  
  // å½•éŸ³çŠ¶æ€
  bool _isInitialized = false;
  bool _isRecording = false;
  
  // éŸ³é¢‘æ•°æ®ç¼“å†²
  List<List<Float32List>> _audioBuffer = [];
  StreamController<List<Float32List>>? _audioDataController;

  YamnetTest() {
    _recorder = FlutterSoundRecorder();
  }

  /// åˆå§‹åŒ–å½•éŸ³å™¨å’Œæ¨¡å‹
  Future<void> initialize() async {
    try {
      if (_isInitialized) {
        print('ğŸ¯ YAMNet test already initialized');
        return;
      }
      
      // åŠ è½½YAMNetæ¨¡å‹
      _interpreter = await Interpreter.fromAsset('assets/model/yamnet.tflite');
      print('ğŸ¯ YAMNet model loaded');
      
      // åŠ è½½æ ‡ç­¾
      String labelsContent = await rootBundle.loadString('assets/model/labels.txt');
      _labels = labelsContent.split('\n').where((line) => line.trim().isNotEmpty).toList();
      print('ğŸ¯ Loaded ${_labels!.length} labels');
      
      // åˆå§‹åŒ–å½•éŸ³å™¨
      print('ğŸ¯ Opening flutter_sound recorder...');
      await _recorder!.openRecorder();
      print('ğŸ¯ Flutter_sound recorder opened successfully');
      
      // è®¾ç½®è®¢é˜…æŒç»­æ—¶é—´
      await _recorder!.setSubscriptionDuration(_subscriptionDuration);
      print('ğŸ¯ Subscription duration set to ${_subscriptionDuration.inMilliseconds}ms');
      
      _isInitialized = true;
      print('ğŸ¯ YAMNet test initialized successfully');
    } catch (e) {
      print('âŒ Failed to initialize: $e');
      rethrow;
    }
  }

  /// åŠ è½½æ¨¡å‹å’Œæ ‡ç­¾ (ä¿æŒå‘åå…¼å®¹)
  Future<void> loadModel() async {
    await initialize();
  }

  /// å¼€å§‹å½•éŸ³
  Future<void> startRecording() async {
    try {
      if (!_isInitialized) {
        await initialize();
      }
      
      if (_isRecording) {
        print('ğŸ¤ Already recording');
        return;
      }
      
      // æ¸…ç©ºä¹‹å‰çš„éŸ³é¢‘ç¼“å†²
      _audioBuffer.clear();
      
      // åˆ›å»ºéŸ³é¢‘æ•°æ®æµæ§åˆ¶å™¨
      _audioDataController = StreamController<List<Float32List>>();
      _audioDataController!.stream.listen((audioData) {
        _audioBuffer.add(audioData);
      });
      
      // å¼€å§‹å½•éŸ³ - ä½¿ç”¨Float32æ ¼å¼ï¼Œé€‚é…YAMNet
      await _recorder!.startRecorder(
        codec: Codec.pcmFloat32,
        sampleRate: _sampleRate,
        numChannels: _numChannels,
        audioSource: AudioSource.defaultSource,
        toStreamFloat32: _audioDataController!.sink,
        bufferSize: _bufferSize,
      );
      
      _isRecording = true;
      print('ğŸ¤ Recording started with Float32 stream');
    } catch (e) {
      print('âŒ Failed to start recording: $e');
      rethrow;
    }
  }

  /// åœæ­¢å½•éŸ³
  Future<List<double>> stopRecording() async {
    try {
      if (!_isRecording) {
        print('ğŸ¤ Not recording');
        return [];
      }
      
      // åœæ­¢å½•éŸ³
      await _recorder!.stopRecorder();
      
      // å…³é—­éŸ³é¢‘æ•°æ®æµæ§åˆ¶å™¨
      await _audioDataController?.close();
      _audioDataController = null;
      
      _isRecording = false;
      
      // ä»éŸ³é¢‘ç¼“å†²ä¸­æå–æ•°æ®
      List<double> audioData = _extractAudioFromBuffer();
      
      print('ğŸ¤ Recording stopped. Length: ${audioData.length}');
      return audioData;
    } catch (e) {
      print('âŒ Failed to stop recording: $e');
      rethrow;
    }
  }
  
  /// ä»éŸ³é¢‘ç¼“å†²ä¸­æå–éŸ³é¢‘æ•°æ®
  List<double> _extractAudioFromBuffer() {
    if (_audioBuffer.isEmpty) {
      print('âš ï¸ No audio data in buffer');
      return [];
    }
    
    List<double> combinedAudio = [];
    
    // åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
    for (var audioData in _audioBuffer) {
      for (var channel in audioData) {
        combinedAudio.addAll(channel);
      }
    }
    
    print('ğŸµ Extracted ${combinedAudio.length} samples from buffer');
    return combinedAudio;
  }

  /// è·å–å½•éŸ³çŠ¶æ€
  bool get isRecording => _isRecording;
  
  /// è·å–åˆå§‹åŒ–çŠ¶æ€
  bool get isInitialized => _isInitialized;
  
  /// è·å–éŸ³é¢‘ç¼“å†²å¤§å°
  int get audioBufferSize => _audioBuffer.length;

  /// åˆ†ç±»éŸ³é¢‘
  Future<List<MapEntry<String, double>>> classifyAudio(List<double> audioData) async {
    try {
      if (_interpreter == null || _labels == null) {
        throw Exception('Model or labels not loaded');
      }
      
      print('ğŸµ Classifying audio...');
      
      // YAMNet TFLiteè¦æ±‚ï¼š0.975ç§’éŸ³é¢‘ (15,600æ ·æœ¬ @ 16kHz)
      int targetLength = 15600; // 0.975 * 16000
      
      if (audioData.length > targetLength) {
        // å¦‚æœéŸ³é¢‘å¤ªé•¿ï¼Œå–ä¸­é—´éƒ¨åˆ†
        int start = (audioData.length - targetLength) ~/ 2;
        audioData = audioData.sublist(start, start + targetLength);
      } else if (audioData.length < targetLength) {
        // å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œç”¨é›¶å¡«å……
        audioData.addAll(List.filled(targetLength - audioData.length, 0.0));
      }
      
      print('ğŸµ Audio length: ${audioData.length} samples (${audioData.length / 16000} seconds)');
      
      // ç›´æ¥ä½¿ç”¨åŸå§‹éŸ³é¢‘æ³¢å½¢ï¼Œä¸éœ€è¦melé¢‘è°±å›¾
      var output = await _runInference(audioData);
      
      // å¤„ç†ç»“æœ
      return _processResults(output);
    } catch (e) {
      print('âŒ Classification error: $e');
      return [];
    }
  }



  /// è¿è¡Œæ¨ç†
  Future<List<double>> _runInference(List<double> audioData) async {
    try {
      // æ£€æŸ¥interpreteræ˜¯å¦ä¸ºç©º
      if (_interpreter == null) {
        throw Exception('Interpreter is null');
      }
      
      // æ£€æŸ¥è¾“å…¥å½¢çŠ¶
      print('ğŸµ Input audio length: ${audioData.length}');
      
      // æ£€æŸ¥æ¨¡å‹è¾“å…¥è¾“å‡ºå½¢çŠ¶
      var inputShape = _interpreter!.getInputTensor(0).shape;
      var outputShape = _interpreter!.getOutputTensor(0).shape;
      print('ğŸµ Model input shape: $inputShape');
      print('ğŸµ Model output shape: $outputShape');
      
      // æ ¹æ®æ¡ˆä¾‹ï¼ŒYAMNet TFLiteæœŸæœ›è¾“å…¥ä¸º2Dæ•°ç»„ [1, 15600]
      var input = [audioData]; // åŒ…è£…æˆ2Dæ•°ç»„ï¼Œä¸æ¡ˆä¾‹ä¸­çš„reshapedInput = [input.toList()]ä¸€è‡´
      
      // æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦ä¸ºç©º
      if (input.isEmpty || input[0].isEmpty) {
        throw Exception('Input audio data is empty');
      }
      
      // å‡†å¤‡è¾“å‡º - æ ¹æ®æ¡ˆä¾‹ï¼Œè¾“å‡ºå½¢çŠ¶ä¸º [1, 521]
      var output = [List<double>.filled(521, 0.0)]; // ä¸æ¡ˆä¾‹ä¸­çš„output = [List<double>.filled(2, 0.0)]ä¸€è‡´
      
      print('ğŸµ Input shape: ${input.length} x ${input[0].length}');
      print('ğŸµ Output shape: ${output.length} x ${output[0].length}');
      
      // æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸ºç©º
      if (output.isEmpty || output[0].isEmpty) {
        throw Exception('Output tensor is empty');
      }
      
      // ä½¿ç”¨å®˜æ–¹æ¨èçš„runæ–¹æ³•
      _interpreter!.run(input, output);
      
      // æ£€æŸ¥è¾“å‡ºç»“æœ
      if (output.isEmpty || output[0].isEmpty) {
        throw Exception('Output is empty after inference');
      }
      
      print('ğŸµ Inference completed successfully');
      return output[0].cast<double>();
    } catch (e) {
      print('âŒ Inference error: $e');
      rethrow;
    }
  }



  /// å¤„ç†ç»“æœ
  List<MapEntry<String, double>> _processResults(List<double> output) {
    List<MapEntry<String, double>> results = [];
    
    // æ£€æŸ¥è¾“å…¥å‚æ•°
    if (output.isEmpty) {
      print('âš ï¸ Output is empty, returning empty results');
      return results;
    }
    
    if (_labels == null || _labels!.isEmpty) {
      print('âš ï¸ Labels are null or empty, returning empty results');
      return results;
    }
    
    print('ğŸµ Processing ${output.length} outputs with ${_labels!.length} labels');
    
    for (int i = 0; i < output.length && i < _labels!.length; i++) {
      double confidence = output[i];
      if (confidence > 0.1) {
        results.add(MapEntry(_labels![i], confidence));
      }
    }
    
    print('ğŸµ Found ${results.length} results with confidence > 0.1');
    results.sort((a, b) => b.value.compareTo(a.value));
    return results.take(10).toList();
  }

  /// æ¸…ç†èµ„æº
  void dispose() {
    try {
      // åœæ­¢å½•éŸ³
      if (_isRecording) {
        _recorder?.stopRecorder();
      }
      
      // å…³é—­éŸ³é¢‘æ•°æ®æµæ§åˆ¶å™¨
      _audioDataController?.close();
      
      // å…³é—­æ¨¡å‹å’Œå½•éŸ³å™¨
      _interpreter?.close();
      _recorder?.closeRecorder();
      
      print('ğŸ¯ YAMNet test disposed');
    } catch (e) {
      print('âŒ Error disposing YAMNet test: $e');
    }
  }
} 